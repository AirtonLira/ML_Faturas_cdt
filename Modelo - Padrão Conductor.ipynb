{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações sobre o notebook\n",
    "- Este notebook deve ser considerado como guia/padrão a ser seguido na construção dos modelos de analise de regra,estatistica e de machine learning pelo time da Conductor.\n",
    "- Todos os codigos abaixo são de exemplo referente aos detalhes que são exigidos de cada etapa.\n",
    "- Todas as funções criadas e o fluxo de processamento dentro do loop são exemplos e não precisar seguir o mesmo padrão.\n",
    "- Considerar que dependendo da quantidade de dados o pandas pode não ser performatico, portanto considerar outras alternativas como pySpark ou Meet Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas\n",
    "- Obrigatorio a utilização das bibliotecas import_ipynb para possibilidade importar outros notebooks como biblioteca e tambem utilizar o utils_cdt como padrão para Importação de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import utils_cdt as cdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções antes do processamento real do notebook\n",
    "- Todo notebook deverá ser executado por pelo menos 3 emissores, com isso o processamento real do notebook será em loop, desta forma, considerar a definição de funções para abstração de manipulações complexas, desta forma facilita a manutenção e execução fora do loop durante o desenvolvimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpezaDados(df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino_e_teste(df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injeção dos dados (obtenção dos dados).\n",
    "- Toda informação inicial, ou seja, todo dataframe bruto (sem manipulação dos dados) deve ser gerado e carregado através de arquivos parquets, portanto é obrigatório o uso da função extrairDados do notebook utils_cdt, a função possui parametros de path e arquivo onde é gerado o arquivo parquet e sempre que for re-executado a função a mesma valida se naquele diretorio+arquivo ja existe o parquet, se existir ele carrega o dataframe de acordo com o tipo especificado (Spark ou pandas) isso evita a re-execução no banco de dados.\n",
    "\n",
    "- Toda query via arquivo deve ser carregada através da função resultQuery, do contrario, caso a query não seja grande pode se utilizar direto no notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulaçao dos dados e criação dos modelos.\n",
    "- Conforme codigo exemplo abaixo, toda a etapa de Manipulaçao dos dados base e criação dos algoritimos de treino deve ser feito considerando um trabalho em loop de pelo menos 3 emissores, isso pode ser feito na entrega final do notebook, no entanto é obrigatorio ser desenvolvido desta forma.\n",
    "\n",
    "- Dica, como o trabalho será feito em loop, considerar as manipulações ou qual quer abstração que se ache interessante em forma de função e definir antes do loop.\n",
    "\n",
    "- Considerar o uso de prints em cada etapa pertinente do notebook, isso facilita o trabalho de deploy para o Databricks onde deve-se conter muitos logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consulta de BASE SQL Server\n",
    "dados_emissores = []\n",
    "dados_emissores.append({\"ip\":\"AZ2D-MASKDB-220.DEVCDT.COM.BR\",\"base\":\"Fortbrasil\"})\n",
    "dados_emissores.append({\"ip\":\"AZ2D-MASKDB-220.DEVCDT.COM.BR\",\"base\":\"Gabriela\"})\n",
    "dados_emissores.append({\"ip\":\"AZ2D-MASKDB-220.DEVCDT.COM.BR\",\"base\":\"Controly\"})\n",
    "\n",
    "\n",
    "consula_modelo = cdt.resultQuery(\"SEU_ARQUIVO.SQL SALVO NA PASTA QUERYS \")\n",
    "consula_treino = cdt.resultQuery(\"SEU_ARQUIVO.SQL SALVO NA PASTA QUERYS \")\n",
    "\n",
    "# Lista com resultado da analise dos emissores. \n",
    "analise_final = []\n",
    "\n",
    "#Loop percorrendo emissores e iniciado as validações\n",
    "for dados in dados_emissores:\n",
    "    print(f\"Iniciado execução do modelo Padrão Conductor para o emissor: {dados[\"base\"]}\")\n",
    "    \n",
    "    df_mdl = cdt.extrairDados(dados,consulta,path=\"DIRETÓRIO ONDE FICA OS ARQUIVOS PARQUETS, GERALMENTE ../data/\",arquivo=\"mdl_iof_rotativo_\"+dados[\"base\"],spark=False,   objSpark=spark)\n",
    "    print(f\"Carregado os dados do modelo\")\n",
    "\n",
    "    df_treino = cdt.extrairDados(dados,consulta,path=\"DIRETÓRIO ONDE FICA OS ARQUIVOS PARQUETS, GERALMENTE ../data/\",arquivo=\"iof_rotativo_treino\"+dados[\"base\"],spark=False,   objSpark=spark)\n",
    "    print(f\"Carregado os dados de treino\")\n",
    "\n",
    "    # Exemplo de limpeza dos dados.\n",
    "    df_limpo = limpezaDados(df_mdl)\n",
    "    print(\"Finalizado limpeza dos dados.\")\n",
    "\n",
    "    # Exemplo de chamado de função para treino e teste.\n",
    "    df_final = treino_e_teste(df_mdl,df_treino)\n",
    "    print(\"Finalizado treino dos dados.\")\n",
    "\n",
    "    # Inserindo resultado final.\n",
    "    analise_final.append({\"Descricao\":f\" Analise do XXXXXXX referente ao emissor: {dados[\"Base\"]}\", \"DataFrame\":df_final})\n",
    "    print(\"Finalizado execução.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('jupyterlab': conda)",
   "language": "python",
   "name": "python37664bitjupyterlabcondadbae0de57a004091ba2937e1d8915e40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
